{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/J-TKim/Gans_in_action/blob/master/Ch8/Ch9_CycleGAN.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩에서 실행하기</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 9-1 패키지 임포트\n",
    "from __future__ import print_function, division\n",
    "import scipy\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow_addons.layers import InstanceNormalization\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 9-2 CycleGAN 클래스\n",
    "class CycleGAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 128\n",
    "        self.img_cols = 128\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        \n",
    "        # 데이터 로더 설정\n",
    "        self.dataset_name = \"apple2orange\"\n",
    "        # DataLoader 객체를 사용해 전처리된 데이터를 임포트합니다.\n",
    "        self.data_loader = DataLoader(dataset_name=self.dataset_name,\n",
    "                                      img_res=(self.img_rows, self.img_cols))\n",
    "        \n",
    "        # D(PatchGAN)의 출력 크기를 계산합니다.\n",
    "        patch = int(self.img_rows / 2**4)\n",
    "        self.disc_patch = (patch, patch + 1)\n",
    "        \n",
    "        # G의 첫 번째 층에 있는 필터의 개수\n",
    "        self.gf = 32\n",
    "        # D의 첫 번째 층에 있는 필터의 개수\n",
    "        self.df = 64\n",
    "        \n",
    "        # 사이클-일관성 손실 가중치\n",
    "        self.lambda_cycle = 10.0\n",
    "        # 동일성 손실 가중치\n",
    "        self.lambda_id = 0.9 * self.lambda_cycle\n",
    "        \n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "        \n",
    "        # 판별자를 만들고 컴파일합니다.\n",
    "        self.d_A = self.build_discriminator()\n",
    "        self.d_B = self.build_discriminator()\n",
    "        self.d_A.compile(loss=\"mse\",\n",
    "                         optimzier=optimizer,\n",
    "                         metrics=[\"accuracy\"])\n",
    "        self.d_B.compile(loss=\"mse\",\n",
    "                         optimzier=optimizer,\n",
    "                         metrics=[\"accuracy\"])\n",
    "        \n",
    "        # 여기서부터 생성자의 계산 그래프를 만듭니다. 처음 두 라인이 생성자를 만듭니다.\n",
    "        self.g_AB = self.build_generator()\n",
    "        self.g_BA = self.build_generator()\n",
    "        \n",
    "        # 두 도메인의 입력 이미지\n",
    "        img_A = Input(shape=self.img_shape)\n",
    "        img_B = Input(shape=self.img_shape)\n",
    "        \n",
    "        # 이미지를 다른 도메인으로 변환합니다.\n",
    "        fake_B = self.g_AB(img_A)\n",
    "        fake_A = self.g_BA(img_B)\n",
    "        \n",
    "        # 원본 도메인으로 이미지를 다시 변환합니다.\n",
    "        reconstr_A = self.g_BA(fake_B)\n",
    "        reconstr_B = self.g_AB(fake_A)\n",
    "        \n",
    "        # 동일한 이미지 매핑\n",
    "        img_A_id = self.g_BA(img_A)\n",
    "        img_B_id = self.g_AB(img_B)\n",
    "        \n",
    "        # 연결 모델에서는 생성자만 훈련 합니다.\n",
    "        self.d_A.trainable = False\n",
    "        self.d_B.trainable = False\n",
    "        \n",
    "        # 판별자가 변환된 이미지의 유효성을 결정합니다.\n",
    "        valid_A = self.d_A(fake_A)\n",
    "        valid_B = self.d_B(fake_B)\n",
    "        \n",
    "        # 연결 모델은 판별자를 속이기 위한 생성자를 훈련합니다.\n",
    "        self.combined = Model(inputs=[img_A, img_B],\n",
    "                              outputs=[valid_A, valid_B,\n",
    "                                       reconstr_A, reconstr_B,\n",
    "                                       img_A_id, img_B_id])\n",
    "        self.combined.compile(loss=[\"mse\", \"mse\",\n",
    "                                    \"mae\", \"mae\",\n",
    "                                    \"mae\", \"mae\"],\n",
    "                              loss_weight=[1, 1,\n",
    "                                           self.lambda_cycle, self.lambda_cycle,\n",
    "                                           self.lambda_id, self.lambda_id],\n",
    "                              optimizer=optimizer)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CycleGAN(CycleGAN):\n",
    "    @staticmethod\n",
    "    def conv2d(layer_input, filters, f_size=4, normalization=True):\n",
    "        \"다운샘플링 하는 동안 사용되는 층\"\n",
    "        d = Conv2D(filters, kernel_size=f_size,\n",
    "                   strides=2, padding=\"same\")(layer_input)\n",
    "        d = LeakyReLU(alpha=0.2)(d)\n",
    "        if normalization:\n",
    "            d = InstanceNormalization()(d)\n",
    "        return d\n",
    "    @staticmethod\n",
    "    def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
    "        \"업샘플링하는 동안 사용되는 층\"\n",
    "        u = UpSampling2D(size=2)(layer_input)\n",
    "        u = Conv2D(filters, kernel_size=f_size, strides=1,\n",
    "                   padding=\"same\", activation=\"relu\")(u)\n",
    "        if dropout_rate:\n",
    "            u = Dropout(dropout_rate)(u)\n",
    "        u = InstanceNormalization()(u)\n",
    "        u = Concatenate()([u, skip_input])\n",
    "        return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CycleGAN(CycleGAN):\n",
    "    def build_generator(self):\n",
    "        \"U-Net 생성자\"\n",
    "        \n",
    "        # 이미지 입력\n",
    "        d0 = Input(shape=self.img_shape)\n",
    "        \n",
    "        # 다운샘플링\n",
    "        d1 = self.conv2d(d0, self.gf)\n",
    "        d2 = self.conv2d(d1, self.gf * 2)\n",
    "        d3 = self.conv2d(d2, self.gf * 4)\n",
    "        d4 = self.conv2d(d3, self.gf * 8)\n",
    "        \n",
    "        # 업샘플링\n",
    "        d5 = self.deconv2d(d4, d3, self.gf * 4)\n",
    "        d6 = self.deconv2d(d5, d2, self.gf * 2)\n",
    "        d7 = self.deconv2d(d6, d1, self.gf)\n",
    "        \n",
    "        u4 = UpSampling2D(size=2)(u3)\n",
    "        output_img = Conv2D(self.channels, kernel_size=4,\n",
    "                            strides=1, padding=\"same\", activation=\"tanh\")(u4)\n",
    "        \n",
    "        return Model(d0, output_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CycleGAN(CycleGAN):\n",
    "    img = Input(shape=self.img_shape)\n",
    "    \n",
    "    d1 = self.conv2d(img, self.df, normalization=False)\n",
    "    d2 = self.conv2d(img, self.df * 2)\n",
    "    d3 = self.conv2d(img, self.df * 4)\n",
    "    d4 = self.conv2d(img, self.df * 8)\n",
    "    \n",
    "    validity = Conv2D(1, kernel_size=4, strides=1, padding=\"same\")(d4)\n",
    "    \n",
    "    return Model(img, validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.1.0-keras2.3.1-py3.6-cuda10.1",
   "language": "python",
   "name": "tf2.1.0-keras2.3.1-py3.6-cuda10.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
